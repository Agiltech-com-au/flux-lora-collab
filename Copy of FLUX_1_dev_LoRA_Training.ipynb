{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1r09aImgL1YhQsJgsLWnb67-bjTV88-W0","timestamp":1732351627328}],"machine_shape":"hm","gpuType":"L4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b3c79f5eee1c4fcd9c021f73f768c752":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_413ea64828794ce68aca8ece8d68cfae","IPY_MODEL_8f3b7de7d2b34eaf92e71e79da776e00","IPY_MODEL_8e7d2fbfc7e9401abdfa9a56e01e6b4d"],"layout":"IPY_MODEL_7de138e2837d433ab030ef9998c15c25"}},"413ea64828794ce68aca8ece8d68cfae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16284544343044359182464484c20a55","placeholder":"​","style":"IPY_MODEL_2442552ed944416dba598496a8fb1076","value":""}},"8f3b7de7d2b34eaf92e71e79da776e00":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e5a0c9d99f54ea0919cb2f304af12c1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_32b5c035b86c4372b74e0d5f2e5f169c","value":0}},"8e7d2fbfc7e9401abdfa9a56e01e6b4d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_783f054ccb6047d38cf4ea5ca31f312b","placeholder":"​","style":"IPY_MODEL_f91e719d6e43418ab453f1f39156cffe","value":" 0/0 [00:00&lt;?, ?it/s]"}},"7de138e2837d433ab030ef9998c15c25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16284544343044359182464484c20a55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2442552ed944416dba598496a8fb1076":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e5a0c9d99f54ea0919cb2f304af12c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"32b5c035b86c4372b74e0d5f2e5f169c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"783f054ccb6047d38cf4ea5ca31f312b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f91e719d6e43418ab453f1f39156cffe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3ce342c2b355443baeaaf794e5d6d3a4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_291c29b2e3b44522812649bedff9c1bb","IPY_MODEL_b5f75bd703b94647bfc8dc8b6e5b9dbf","IPY_MODEL_e9841363df0b49599255f6a8dabe7cac"],"layout":"IPY_MODEL_bd9731ef65fa4091a199a3a4976d1568"}},"291c29b2e3b44522812649bedff9c1bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_da28bff50dbb45c687fe0ec7d0fcd738","placeholder":"​","style":"IPY_MODEL_71d877fc232c4e18a8d3697e8d6da6a5","value":"transformer/config.json: 100%"}},"b5f75bd703b94647bfc8dc8b6e5b9dbf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb8386990ec348ceb280dbc3c3a44d47","max":378,"min":0,"orientation":"horizontal","style":"IPY_MODEL_92fc06eb5e83482d8b573c675e10ca8f","value":378}},"e9841363df0b49599255f6a8dabe7cac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23c456524a90445a823b65b70d13a37e","placeholder":"​","style":"IPY_MODEL_95f0a5474a5643ffac5219428cb74dca","value":" 378/378 [00:00&lt;00:00, 22.9kB/s]"}},"bd9731ef65fa4091a199a3a4976d1568":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da28bff50dbb45c687fe0ec7d0fcd738":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71d877fc232c4e18a8d3697e8d6da6a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb8386990ec348ceb280dbc3c3a44d47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92fc06eb5e83482d8b573c675e10ca8f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"23c456524a90445a823b65b70d13a37e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95f0a5474a5643ffac5219428cb74dca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f9dc90994574cac992aaebdb8c78535":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_439c9b090f844c0792d7294e7edc9093","IPY_MODEL_28763fc0633b401dacf9f06103f92a20","IPY_MODEL_a806648c480745df975b489ed0da1b46"],"layout":"IPY_MODEL_f0328039671a4c90b8b652063cd2566e"}},"439c9b090f844c0792d7294e7edc9093":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01196e5962f542c09afc48a5b7d9c30c","placeholder":"​","style":"IPY_MODEL_7ca96faa4991400998dcb751f761dcd2","value":"(…)ion_pytorch_model.safetensors.index.json: 100%"}},"28763fc0633b401dacf9f06103f92a20":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bca6d34888a4d189b4306cfc45eaa7e","max":121262,"min":0,"orientation":"horizontal","style":"IPY_MODEL_66184b11df9d42e49aa24799d20f4d5e","value":121262}},"a806648c480745df975b489ed0da1b46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_519a6b25b54a43c8bd89b8a704d72098","placeholder":"​","style":"IPY_MODEL_21ee870b605b41619e51977c636aa367","value":" 121k/121k [00:00&lt;00:00, 5.44MB/s]"}},"f0328039671a4c90b8b652063cd2566e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01196e5962f542c09afc48a5b7d9c30c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ca96faa4991400998dcb751f761dcd2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3bca6d34888a4d189b4306cfc45eaa7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66184b11df9d42e49aa24799d20f4d5e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"519a6b25b54a43c8bd89b8a704d72098":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21ee870b605b41619e51977c636aa367":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9d4a5a78510f4425969ec93af9819ec7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_791ede0294994e0d931ce85fba42fc87","IPY_MODEL_7f3eb2094fd544d5ae63f83aa609f8d4","IPY_MODEL_ca01715a9ae544f8b2168369477b8e2a"],"layout":"IPY_MODEL_3cde4a9a466746d2a714333482da4d71"}},"791ede0294994e0d931ce85fba42fc87":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e4c7b55c6114a32b04d162d61c24fbb","placeholder":"​","style":"IPY_MODEL_36f1f0e9fda44fb49d1254cf2e5bdeaf","value":"(…)pytorch_model-00001-of-00003.safetensors: 100%"}},"7f3eb2094fd544d5ae63f83aa609f8d4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d129d573fee438ba972705b2771e614","max":9983040304,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3e504140d09949d0a034819490d6e04e","value":9983039352}},"ca01715a9ae544f8b2168369477b8e2a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a38aee584a074e62bf12aad6403578c1","placeholder":"​","style":"IPY_MODEL_17749fb290b3457ea58f989d2a781cc3","value":" 9.98G/9.98G [01:24&lt;00:00, 52.7MB/s]"}},"3cde4a9a466746d2a714333482da4d71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e4c7b55c6114a32b04d162d61c24fbb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36f1f0e9fda44fb49d1254cf2e5bdeaf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d129d573fee438ba972705b2771e614":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e504140d09949d0a034819490d6e04e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a38aee584a074e62bf12aad6403578c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17749fb290b3457ea58f989d2a781cc3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f2e4910fa8a04ba6bcc57cb17c839c0e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5fd512d3ccf84e9d805a4771b8fc79fa","IPY_MODEL_e6a9ab9185144bd1933c76c55b015473","IPY_MODEL_1dcc43e40935413da0b77156f6e57b14"],"layout":"IPY_MODEL_42562d9621724a19b7840f3c83b407f7"}},"5fd512d3ccf84e9d805a4771b8fc79fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_077182d5f2e04a9b850c8efd30d488c7","placeholder":"​","style":"IPY_MODEL_40f625ce2e494e91ae547bb6f2ed9cef","value":"(…)pytorch_model-00002-of-00003.safetensors: 100%"}},"e6a9ab9185144bd1933c76c55b015473":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5291920b78d4650a5e530d6ea231ae7","max":9949328904,"min":0,"orientation":"horizontal","style":"IPY_MODEL_138ada7f51814c2da04e6b5feefb48c8","value":9949327956}},"1dcc43e40935413da0b77156f6e57b14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5862d496ad3146b4b1b3592e68fc0af9","placeholder":"​","style":"IPY_MODEL_643b77fed95f4788860cc48c06ede22d","value":" 9.95G/9.95G [01:14&lt;00:00, 90.2MB/s]"}},"42562d9621724a19b7840f3c83b407f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"077182d5f2e04a9b850c8efd30d488c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40f625ce2e494e91ae547bb6f2ed9cef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5291920b78d4650a5e530d6ea231ae7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"138ada7f51814c2da04e6b5feefb48c8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5862d496ad3146b4b1b3592e68fc0af9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"643b77fed95f4788860cc48c06ede22d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"512d9cea35134017bd6cc3cfadef9e8e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a216ff4ebb9c43e0928ff9d71cd8f6ef","IPY_MODEL_6a66757ae448417c8a0c8065b10f0e58","IPY_MODEL_483084b06ee147cca9e06ca0d2d33525"],"layout":"IPY_MODEL_a0d0a06cbe534bd78374cb8becb9a46d"}},"a216ff4ebb9c43e0928ff9d71cd8f6ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43ed38a849d246fbad2705ca249cda6a","placeholder":"​","style":"IPY_MODEL_bbfc024deb304aa0ba41db34cab3dcb1","value":"(…)pytorch_model-00003-of-00003.safetensors: 100%"}},"6a66757ae448417c8a0c8065b10f0e58":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_dda0df5717df4058ae695c7c0165c9c1","max":3870584832,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2b1526aa16c3449c92a4d08d5f5b9558","value":3870584463}},"483084b06ee147cca9e06ca0d2d33525":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_601ccde8b5b94a06823d3a58003768f5","placeholder":"​","style":"IPY_MODEL_09fb7de9d4354a36bd9975b9c924042b","value":" 3.87G/3.87G [00:37&lt;00:00, 231MB/s]"}},"a0d0a06cbe534bd78374cb8becb9a46d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43ed38a849d246fbad2705ca249cda6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbfc024deb304aa0ba41db34cab3dcb1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dda0df5717df4058ae695c7c0165c9c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b1526aa16c3449c92a4d08d5f5b9558":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"601ccde8b5b94a06823d3a58003768f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09fb7de9d4354a36bd9975b9c924042b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# AI Toolkit by Ostris\n","## FLUX.1 Training\n"],"metadata":{"collapsed":false,"id":"zl-S0m3pkQC5"}},{"cell_type":"code","source":["!git clone https://github.com/ostris/ai-toolkit\n","!mkdir -p /content/dataset"],"metadata":{"id":"BvAG0GKAh59G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Put your image dataset in the `/content/dataset` folder"],"metadata":{"id":"UFUW4ZMmnp1V"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"XGZqVER_aQJW","executionInfo":{"status":"ok","timestamp":1732349645898,"user_tz":-660,"elapsed":55682,"user":{"displayName":"Richard","userId":"13391767967279829163"}},"outputId":"314619a3-44f6-4373-ce03-dba2ce8f33b1","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Submodule 'repositories/batch_annotator' (https://github.com/ostris/batch-annotator) registered for path 'repositories/batch_annotator'\n","Submodule 'repositories/ipadapter' (https://github.com/tencent-ailab/IP-Adapter.git) registered for path 'repositories/ipadapter'\n","Submodule 'repositories/leco' (https://github.com/p1atdev/LECO) registered for path 'repositories/leco'\n","Submodule 'repositories/sd-scripts' (https://github.com/kohya-ss/sd-scripts.git) registered for path 'repositories/sd-scripts'\n","Cloning into '/content/ai-toolkit/repositories/batch_annotator'...\n","Cloning into '/content/ai-toolkit/repositories/ipadapter'...\n","Cloning into '/content/ai-toolkit/repositories/leco'...\n","Cloning into '/content/ai-toolkit/repositories/sd-scripts'...\n","Submodule path 'repositories/batch_annotator': checked out '420e142f6ad3cc14b3ea0500affc2c6c7e7544bf'\n","Submodule 'repositories/controlnet' (https://github.com/lllyasviel/ControlNet-v1-1-nightly.git) registered for path 'repositories/batch_annotator/repositories/controlnet'\n","Cloning into '/content/ai-toolkit/repositories/batch_annotator/repositories/controlnet'...\n","Submodule path 'repositories/batch_annotator/repositories/controlnet': checked out 'e2b44154b72965c5e11b1ccee941d550682e4701'\n","Submodule path 'repositories/ipadapter': checked out '5a18b1f3660acaf8bee8250692d6fb3548a19b14'\n","Submodule path 'repositories/leco': checked out '9294adf40218e917df4516737afb13f069a6789d'\n","Submodule path 'repositories/sd-scripts': checked out 'b78c0e2a69e52ce6c79abc6c8c82d1a9cabcf05c'\n","Collecting git+https://github.com/huggingface/diffusers.git (from -r requirements.txt (line 4))\n","  Cloning https://github.com/huggingface/diffusers.git to /tmp/pip-req-build-sjtuy0bq\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers.git /tmp/pip-req-build-sjtuy0bq\n","  Resolved https://github.com/huggingface/diffusers.git to commit b5fd6f13f5434d69d919cc8cedf0b11db664cf06\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.5.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.20.1+cu121)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.4.5)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.46.2)\n","Collecting lycoris-lora==1.8.3 (from -r requirements.txt (line 6))\n","  Downloading lycoris_lora-1.8.3.tar.gz (96 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting flatten_json (from -r requirements.txt (line 7))\n","  Downloading flatten_json-0.1.14-py3-none-any.whl.metadata (4.2 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (6.0.2)\n","Collecting oyaml (from -r requirements.txt (line 9))\n","  Downloading oyaml-1.0-py2.py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (2.17.1)\n","Collecting kornia (from -r requirements.txt (line 11))\n","  Downloading kornia-0.7.4-py2.py3-none-any.whl.metadata (18 kB)\n","Collecting invisible-watermark (from -r requirements.txt (line 12))\n","  Downloading invisible_watermark-0.2.0-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (0.8.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (1.1.1)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (0.10.2)\n","Collecting albumentations==1.4.15 (from -r requirements.txt (line 16))\n","  Downloading albumentations-1.4.15-py3-none-any.whl.metadata (38 kB)\n","Collecting albucore==0.0.16 (from -r requirements.txt (line 17))\n","  Downloading albucore-0.0.16-py3-none-any.whl.metadata (3.1 kB)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (2.9.2)\n","Collecting omegaconf (from -r requirements.txt (line 19))\n","  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n","Collecting k-diffusion (from -r requirements.txt (line 20))\n","  Downloading k_diffusion-0.1.1.post1-py3-none-any.whl.metadata (3.9 kB)\n","Collecting open_clip_torch (from -r requirements.txt (line 21))\n","  Downloading open_clip_torch-2.29.0-py3-none-any.whl.metadata (31 kB)\n","Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (1.0.11)\n","Collecting prodigyopt (from -r requirements.txt (line 23))\n","  Downloading prodigyopt-1.0-py3-none-any.whl.metadata (1.2 kB)\n","Collecting controlnet_aux==0.0.7 (from -r requirements.txt (line 24))\n","  Downloading controlnet_aux-0.0.7.tar.gz (202 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.4/202.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting python-dotenv (from -r requirements.txt (line 25))\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Collecting bitsandbytes (from -r requirements.txt (line 26))\n","  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n","Collecting hf_transfer (from -r requirements.txt (line 27))\n","  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n","Collecting lpips (from -r requirements.txt (line 28))\n","  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\n","Collecting pytorch_fid (from -r requirements.txt (line 29))\n","  Downloading pytorch_fid-0.3.0-py3-none-any.whl.metadata (5.3 kB)\n","Collecting optimum-quanto==0.2.4 (from -r requirements.txt (line 30))\n","  Downloading optimum_quanto-0.2.4-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 31)) (0.2.0)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 32)) (0.26.2)\n","Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 33)) (0.13.2)\n","Collecting gradio (from -r requirements.txt (line 34))\n","  Downloading gradio-5.6.0-py3-none-any.whl.metadata (16 kB)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (8.0.4)\n","Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (1.26.4)\n","Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (1.13.1)\n","Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (0.24.0)\n","Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (0.2.0)\n","Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (4.10.0.84)\n","Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.10/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (8.5.0)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (4.10.0.84)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (3.16.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (11.0.0)\n","Collecting ninja (from optimum-quanto==0.2.4->-r requirements.txt (line 30))\n","  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.32.0.dev0->-r requirements.txt (line 4)) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.32.0.dev0->-r requirements.txt (line 4)) (2.32.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (24.2)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (0.20.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (4.66.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from flatten_json->-r requirements.txt (line 7)) (1.16.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.68.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (3.7)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (4.25.5)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (75.1.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (3.1.3)\n","Collecting kornia-rs>=0.1.0 (from kornia->-r requirements.txt (line 11))\n","  Downloading kornia_rs-0.1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n","Collecting PyWavelets>=1.1.1 (from invisible-watermark->-r requirements.txt (line 12))\n","  Downloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 14)) (5.9.5)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->-r requirements.txt (line 18)) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->-r requirements.txt (line 18)) (2.23.4)\n","Collecting antlr4-python3-runtime==4.9.* (from omegaconf->-r requirements.txt (line 19))\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting clean-fid (from k-diffusion->-r requirements.txt (line 20))\n","  Downloading clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)\n","Collecting clip-anytorch (from k-diffusion->-r requirements.txt (line 20))\n","  Downloading clip_anytorch-2.6.0-py3-none-any.whl.metadata (8.4 kB)\n","Collecting dctorch (from k-diffusion->-r requirements.txt (line 20))\n","  Downloading dctorch-0.1.2-py3-none-any.whl.metadata (607 bytes)\n","Collecting jsonmerge (from k-diffusion->-r requirements.txt (line 20))\n","  Downloading jsonmerge-1.9.2-py3-none-any.whl.metadata (21 kB)\n","Collecting torchdiffeq (from k-diffusion->-r requirements.txt (line 20))\n","  Downloading torchdiffeq-0.2.5-py3-none-any.whl.metadata (440 bytes)\n","Collecting torchsde (from k-diffusion->-r requirements.txt (line 20))\n","  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from k-diffusion->-r requirements.txt (line 20)) (0.18.7)\n","Collecting ftfy (from open_clip_torch->-r requirements.txt (line 21))\n","  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n","Collecting aiofiles<24.0,>=22.0 (from gradio->-r requirements.txt (line 34))\n","  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (3.7.1)\n","Collecting fastapi<1.0,>=0.115.2 (from gradio->-r requirements.txt (line 34))\n","  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n","Collecting ffmpy (from gradio->-r requirements.txt (line 34))\n","  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n","Collecting gradio-client==1.4.3 (from gradio->-r requirements.txt (line 34))\n","  Downloading gradio_client-1.4.3-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (0.27.2)\n","Collecting markupsafe~=2.0 (from gradio->-r requirements.txt (line 34))\n","  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (3.10.11)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (2.2.2)\n","Collecting pydub (from gradio->-r requirements.txt (line 34))\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting python-multipart==0.0.12 (from gradio->-r requirements.txt (line 34))\n","  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n","Collecting ruff>=0.2.2 (from gradio->-r requirements.txt (line 34))\n","  Downloading ruff-0.8.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n","Collecting safehttpx<1.0,>=0.1.1 (from gradio->-r requirements.txt (line 34))\n","  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n","Collecting semantic-version~=2.0 (from gradio->-r requirements.txt (line 34))\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting starlette<1.0,>=0.40.0 (from gradio->-r requirements.txt (line 34))\n","  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n","Collecting tomlkit==0.12.0 (from gradio->-r requirements.txt (line 34))\n","  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (0.13.0)\n","Collecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 34))\n","  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n","Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.3->gradio->-r requirements.txt (line 34))\n","  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->-r requirements.txt (line 35)) (1.3)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 34)) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 34)) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 34)) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 34)) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 34)) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio->-r requirements.txt (line 34)) (0.14.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 34)) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 34)) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 34)) (2024.2)\n","Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 16)) (2.36.0)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 16)) (2024.9.20)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 16)) (0.4)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (13.9.4)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->open_clip_torch->-r requirements.txt (line 21)) (0.2.13)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata->controlnet_aux==0.0.7->-r requirements.txt (line 24)) (3.21.0)\n","Requirement already satisfied: jsonschema>2.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonmerge->k-diffusion->-r requirements.txt (line 20)) (4.23.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.32.0.dev0->-r requirements.txt (line 4)) (3.4.0)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.32.0.dev0->-r requirements.txt (line 4)) (2.2.3)\n","Collecting trampoline>=0.1.2 (from torchsde->k-diffusion->-r requirements.txt (line 20))\n","  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (3.1.43)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (4.3.6)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (2.18.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (1.3.4)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->k-diffusion->-r requirements.txt (line 20)) (4.0.11)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (24.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (0.21.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (2.18.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->k-diffusion->-r requirements.txt (line 20)) (5.0.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (0.1.2)\n","Downloading albumentations-1.4.15-py3-none-any.whl (200 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading albucore-0.0.16-py3-none-any.whl (9.5 kB)\n","Downloading optimum_quanto-0.2.4-py3-none-any.whl (109 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.7/109.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading flatten_json-0.1.14-py3-none-any.whl (8.0 kB)\n","Downloading oyaml-1.0-py2.py3-none-any.whl (3.0 kB)\n","Downloading kornia-0.7.4-py2.py3-none-any.whl (899 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.4/899.4 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading invisible_watermark-0.2.0-py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading k_diffusion-0.1.1.post1-py3-none-any.whl (33 kB)\n","Downloading open_clip_torch-2.29.0-py3-none-any.whl (1.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading prodigyopt-1.0-py3-none-any.whl (5.5 kB)\n","Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lpips-0.1.4-py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\n","Downloading gradio-5.6.0-py3-none-any.whl (57.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio_client-1.4.3-py3-none-any.whl (320 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n","Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n","Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading kornia_rs-0.1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n","Downloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ruff-0.8.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n","Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading clean_fid-0.1.35-py3-none-any.whl (26 kB)\n","Downloading clip_anytorch-2.6.0-py3-none-any.whl (1.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dctorch-0.1.2-py3-none-any.whl (2.3 kB)\n","Downloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n","Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonmerge-1.9.2-py3-none-any.whl (19 kB)\n","Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Downloading torchdiffeq-0.2.5-py3-none-any.whl (32 kB)\n","Downloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n","Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: lycoris-lora, controlnet_aux, diffusers, antlr4-python3-runtime\n","  Building wheel for lycoris-lora (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lycoris-lora: filename=lycoris_lora-1.8.3-py3-none-any.whl size=77134 sha256=6174b72f6a5af6806c5d9b178ae1e3feec2d1e1683dd60d0f32ff93aa000fae0\n","  Stored in directory: /root/.cache/pip/wheels/1b/d8/ac/e1feba5dec18685dac32ff2465ea1908cbe6a919a0c008a215\n","  Building wheel for controlnet_aux (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for controlnet_aux: filename=controlnet_aux-0.0.7-py3-none-any.whl size=274344 sha256=f8948a8c34b3a3158e771faa55264acf52ef64057b04cf8f993143399d77495f\n","  Stored in directory: /root/.cache/pip/wheels/1e/3e/93/6678b4c0bc2ec31d53409b25d4189cbb08bae843e8b2b78e52\n","  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for diffusers: filename=diffusers-0.32.0.dev0-py3-none-any.whl size=2940410 sha256=1f3ff5d5904bf0eaf37a7812d5f4872df95ccb9e9b7c2c032a259e4e73614c46\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-3cvn814e/wheels/4d/b7/a8/6f9549ceec5daad78675b857ac57d697c387062506520a7b50\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=7b7b5ce3770fdd9438daf3f9156cc905c4c0cdf846b7d37c60118bb10f8b2cad\n","  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n","Successfully built lycoris-lora controlnet_aux diffusers antlr4-python3-runtime\n","Installing collected packages: trampoline, pydub, ninja, antlr4-python3-runtime, websockets, uvicorn, tomlkit, semantic-version, ruff, PyWavelets, python-multipart, python-dotenv, prodigyopt, oyaml, omegaconf, markupsafe, kornia-rs, hf_transfer, ftfy, flatten_json, ffmpy, aiofiles, starlette, albucore, safehttpx, gradio-client, fastapi, diffusers, albumentations, torchsde, torchdiffeq, optimum-quanto, kornia, jsonmerge, invisible-watermark, gradio, dctorch, bitsandbytes, pytorch_fid, lycoris-lora, lpips, clip-anytorch, clean-fid, open_clip_torch, k-diffusion, controlnet_aux\n","  Attempting uninstall: markupsafe\n","    Found existing installation: MarkupSafe 3.0.2\n","    Uninstalling MarkupSafe-3.0.2:\n","      Successfully uninstalled MarkupSafe-3.0.2\n","  Attempting uninstall: albucore\n","    Found existing installation: albucore 0.0.19\n","    Uninstalling albucore-0.0.19:\n","      Successfully uninstalled albucore-0.0.19\n","  Attempting uninstall: diffusers\n","    Found existing installation: diffusers 0.31.0\n","    Uninstalling diffusers-0.31.0:\n","      Successfully uninstalled diffusers-0.31.0\n","  Attempting uninstall: albumentations\n","    Found existing installation: albumentations 1.4.20\n","    Uninstalling albumentations-1.4.20:\n","      Successfully uninstalled albumentations-1.4.20\n","Successfully installed PyWavelets-1.7.0 aiofiles-23.2.1 albucore-0.0.16 albumentations-1.4.15 antlr4-python3-runtime-4.9.3 bitsandbytes-0.44.1 clean-fid-0.1.35 clip-anytorch-2.6.0 controlnet_aux-0.0.7 dctorch-0.1.2 diffusers-0.32.0.dev0 fastapi-0.115.5 ffmpy-0.4.0 flatten_json-0.1.14 ftfy-6.3.1 gradio-5.6.0 gradio-client-1.4.3 hf_transfer-0.1.8 invisible-watermark-0.2.0 jsonmerge-1.9.2 k-diffusion-0.1.1.post1 kornia-0.7.4 kornia-rs-0.1.7 lpips-0.1.4 lycoris-lora-1.8.3 markupsafe-2.1.5 ninja-1.11.1.1 omegaconf-2.3.0 open_clip_torch-2.29.0 optimum-quanto-0.2.4 oyaml-1.0 prodigyopt-1.0 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.12 pytorch_fid-0.3.0 ruff-0.8.0 safehttpx-0.1.1 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.12.0 torchdiffeq-0.2.5 torchsde-0.2.6 trampoline-0.1.2 uvicorn-0.32.1 websockets-12.0\n"]}],"source":["!cd ai-toolkit && git submodule update --init --recursive && pip install -r requirements.txt\n"]},{"cell_type":"markdown","source":["## Model License\n","Training currently only works with FLUX.1-dev. Which means anything you train will inherit the non-commercial license. It is also a gated model, so you need to accept the license on HF before using it. Otherwise, this will fail. Here are the required steps to setup a license.\n","\n","Sign into HF and accept the model access here [black-forest-labs/FLUX.1-dev](https://huggingface.co/black-forest-labs/FLUX.1-dev)\n","\n","[Get a READ key from huggingface](https://huggingface.co/settings/tokens/new?) and place it in the next cell after running it."],"metadata":{"id":"OV0HnOI6o8V6"}},{"cell_type":"code","source":["import getpass\n","import os\n","\n","# Prompt for the token\n","hf_token = getpass.getpass('Enter your HF access token and press enter: ')\n","\n","# Set the environment variable\n","os.environ['HF_TOKEN'] = hf_token\n","\n","print(\"HF_TOKEN environment variable has been set.\")"],"metadata":{"id":"3yZZdhFRoj2m","executionInfo":{"status":"ok","timestamp":1732351090552,"user_tz":-660,"elapsed":4121,"user":{"displayName":"Richard","userId":"13391767967279829163"}},"outputId":"87ff0022-b263-4386-c1cc-e5434c429c35","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter your HF access token and press enter: ··········\n","HF_TOKEN environment variable has been set.\n"]}]},{"cell_type":"code","source":["import os\n","import sys\n","sys.path.append('/content/ai-toolkit')\n","from toolkit.job import run_job\n","from collections import OrderedDict\n","from PIL import Image\n","import os\n","os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\""],"metadata":{"id":"9gO2EzQ1kQC8","executionInfo":{"status":"ok","timestamp":1732351093134,"user_tz":-660,"elapsed":481,"user":{"displayName":"Richard","userId":"13391767967279829163"}}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["## Setup\n","\n","This is your config. It is documented pretty well. Normally you would do this as a yaml file, but for colab, this will work. This will run as is without modification, but feel free to edit as you want."],"metadata":{"id":"N8UUFzVRigbC"}},{"cell_type":"code","source":["from collections import OrderedDict\n","\n","job_to_run = OrderedDict([\n","    ('job', 'extension'),\n","    ('config', OrderedDict([\n","        # this name will be the folder and filename name\n","        ('name', 'my_first_flux_lora_v1'),\n","        ('process', [\n","            OrderedDict([\n","                ('type', 'sd_trainer'),\n","                # root folder to save training sessions/samples/weights\n","                ('training_folder', '/content/output'),\n","                # uncomment to see performance stats in the terminal every N steps\n","                #('performance_log_every', 1000),\n","                ('device', 'cuda:0'),\n","                # if a trigger word is specified, it will be added to captions of training data if it does not already exist\n","                # alternatively, in your captions you can add [trigger] and it will be replaced with the trigger word\n","                # ('trigger_word', 'image'),\n","                ('network', OrderedDict([\n","                    ('type', 'lora'),\n","                    ('linear', 16),\n","                    ('linear_alpha', 16)\n","                ])),\n","                ('save', OrderedDict([\n","                    ('dtype', 'float16'),  # precision to save\n","                    ('save_every', 250),  # save every this many steps\n","                    ('max_step_saves_to_keep', 4)  # how many intermittent saves to keep\n","                ])),\n","                ('datasets', [\n","                    # datasets are a folder of images. captions need to be txt files with the same name as the image\n","                    # for instance image2.jpg and image2.txt. Only jpg, jpeg, and png are supported currently\n","                    # images will automatically be resized and bucketed into the resolution specified\n","                    OrderedDict([\n","                        ('folder_path', '/content/dataset'),\n","                        ('caption_ext', 'txt'),\n","                        ('caption_dropout_rate', 0.05),  # will drop out the caption 5% of time\n","                        ('shuffle_tokens', False),  # shuffle caption order, split by commas\n","                        ('cache_latents_to_disk', True),  # leave this true unless you know what you're doing\n","                        ('resolution', [512, 768, 1024])  # flux enjoys multiple resolutions\n","                    ])\n","                ]),\n","                ('train', OrderedDict([\n","                    ('batch_size', 1),\n","                    ('steps', 4000),  # total number of steps to train 500 - 4000 is a good range\n","                    ('gradient_accumulation_steps', 1),\n","                    ('train_unet', True),\n","                    ('train_text_encoder', False),  # probably won't work with flux\n","                    ('content_or_style', 'balanced'),  # content, style, balanced\n","                    ('gradient_checkpointing', True),  # need the on unless you have a ton of vram\n","                    ('noise_scheduler', 'flowmatch'),  # for training only\n","                    ('optimizer', 'adamw8bit'),\n","                    ('lr', 4e-4),\n","                    # uncomment this to skip the pre training sample\n","                    #('skip_first_sample', True),\n","\n","                    # ema will smooth out learning, but could slow it down. Recommended to leave on.\n","                    ('ema_config', OrderedDict([\n","                        ('use_ema', True),\n","                        ('ema_decay', 0.99)\n","                    ])),\n","\n","                    # will probably need this if gpu supports it for flux, other dtypes may not work correctly\n","                    ('dtype', 'bf16')\n","                ])),\n","                ('model', OrderedDict([\n","                    # huggingface model name or path\n","                    ('name_or_path', 'black-forest-labs/FLUX.1-dev'),\n","                    ('is_flux', True),\n","                    ('quantize', True),  # run 8bit mixed precision\n","                    #('low_vram', True),  # uncomment this if the GPU is connected to your monitors. It will use less vram to quantize, but is slower.\n","                ])),\n","                ('sample', OrderedDict([\n","                    ('sampler', 'flowmatch'),  # must match train.noise_scheduler\n","                    ('sample_every', 250),  # sample every this many steps\n","                    ('width', 1024),\n","                    ('height', 1024),\n","                    ('prompts', [\n","                        # you can add [trigger] to the prompts here and it will be replaced with the trigger word\n","                        #'[trigger] holding a sign that says \\'I LOVE PROMPTS!\\'',\n","                        'my_first_flux_lora_v1',\n","                        'my_first_flux_lora_v1',\n","                        'my_first_flux_lora_v1',\n","                        'my_first_flux_lora_v1',\n","                        'my_first_flux_lora_v1',\n","                        'my_first_flux_lora_v1',\n","                        'my_first_flux_lora_v1',\n","                        'my_first_flux_lora_v1',\n","                        'my_first_flux_lora_v1',\n","                    ]),\n","                    ('neg', ''),  # not used on flux\n","                    ('seed', 42),\n","                    ('walk_seed', True),\n","                    ('guidance_scale', 4),\n","                    ('sample_steps', 20)\n","                ]))\n","            ])\n","        ])\n","    ])),\n","    # you can add any additional meta info here. [name] is replaced with config name at top\n","    ('meta', OrderedDict([\n","        ('name', '[name]'),\n","        ('version', '1.0')\n","    ]))\n","])\n"],"metadata":{"id":"_t28QURYjRQO","executionInfo":{"status":"ok","timestamp":1732351199588,"user_tz":-660,"elapsed":315,"user":{"displayName":"Richard","userId":"13391767967279829163"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Run it\n","\n","Below does all the magic. Check your folders to the left. Items will be in output/LoRA/your_name_v1 In the samples folder, there are preiodic sampled. This doesnt work great with colab. They will be in /content/output"],"metadata":{"id":"h6F1FlM2Wb3l"}},{"cell_type":"code","source":["run_job(job_to_run)\n"],"metadata":{"id":"HkajwI8gteOh","executionInfo":{"status":"error","timestamp":1732351500885,"user_tz":-660,"elapsed":289680,"user":{"displayName":"Richard","userId":"13391767967279829163"}},"outputId":"939bed1d-4b0a-4934-f171-2d0155b86317","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["b3c79f5eee1c4fcd9c021f73f768c752","413ea64828794ce68aca8ece8d68cfae","8f3b7de7d2b34eaf92e71e79da776e00","8e7d2fbfc7e9401abdfa9a56e01e6b4d","7de138e2837d433ab030ef9998c15c25","16284544343044359182464484c20a55","2442552ed944416dba598496a8fb1076","5e5a0c9d99f54ea0919cb2f304af12c1","32b5c035b86c4372b74e0d5f2e5f169c","783f054ccb6047d38cf4ea5ca31f312b","f91e719d6e43418ab453f1f39156cffe","3ce342c2b355443baeaaf794e5d6d3a4","291c29b2e3b44522812649bedff9c1bb","b5f75bd703b94647bfc8dc8b6e5b9dbf","e9841363df0b49599255f6a8dabe7cac","bd9731ef65fa4091a199a3a4976d1568","da28bff50dbb45c687fe0ec7d0fcd738","71d877fc232c4e18a8d3697e8d6da6a5","bb8386990ec348ceb280dbc3c3a44d47","92fc06eb5e83482d8b573c675e10ca8f","23c456524a90445a823b65b70d13a37e","95f0a5474a5643ffac5219428cb74dca","8f9dc90994574cac992aaebdb8c78535","439c9b090f844c0792d7294e7edc9093","28763fc0633b401dacf9f06103f92a20","a806648c480745df975b489ed0da1b46","f0328039671a4c90b8b652063cd2566e","01196e5962f542c09afc48a5b7d9c30c","7ca96faa4991400998dcb751f761dcd2","3bca6d34888a4d189b4306cfc45eaa7e","66184b11df9d42e49aa24799d20f4d5e","519a6b25b54a43c8bd89b8a704d72098","21ee870b605b41619e51977c636aa367","9d4a5a78510f4425969ec93af9819ec7","791ede0294994e0d931ce85fba42fc87","7f3eb2094fd544d5ae63f83aa609f8d4","ca01715a9ae544f8b2168369477b8e2a","3cde4a9a466746d2a714333482da4d71","2e4c7b55c6114a32b04d162d61c24fbb","36f1f0e9fda44fb49d1254cf2e5bdeaf","1d129d573fee438ba972705b2771e614","3e504140d09949d0a034819490d6e04e","a38aee584a074e62bf12aad6403578c1","17749fb290b3457ea58f989d2a781cc3","f2e4910fa8a04ba6bcc57cb17c839c0e","5fd512d3ccf84e9d805a4771b8fc79fa","e6a9ab9185144bd1933c76c55b015473","1dcc43e40935413da0b77156f6e57b14","42562d9621724a19b7840f3c83b407f7","077182d5f2e04a9b850c8efd30d488c7","40f625ce2e494e91ae547bb6f2ed9cef","a5291920b78d4650a5e530d6ea231ae7","138ada7f51814c2da04e6b5feefb48c8","5862d496ad3146b4b1b3592e68fc0af9","643b77fed95f4788860cc48c06ede22d","512d9cea35134017bd6cc3cfadef9e8e","a216ff4ebb9c43e0928ff9d71cd8f6ef","6a66757ae448417c8a0c8065b10f0e58","483084b06ee147cca9e06ca0d2d33525","a0d0a06cbe534bd78374cb8becb9a46d","43ed38a849d246fbad2705ca249cda6a","bbfc024deb304aa0ba41db34cab3dcb1","dda0df5717df4058ae695c7c0165c9c1","2b1526aa16c3449c92a4d08d5f5b9558","601ccde8b5b94a06823d3a58003768f5","09fb7de9d4354a36bd9975b9c924042b"]}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3c79f5eee1c4fcd9c021f73f768c752"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n","  check_for_updates()\n","/usr/local/lib/python3.10/dist-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n","  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n","/usr/local/lib/python3.10/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n","  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n","/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_5m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  return register_model(fn_wrapper)\n","/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_11m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  return register_model(fn_wrapper)\n","/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  return register_model(fn_wrapper)\n","/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_384 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  return register_model(fn_wrapper)\n","/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_512 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n","  return register_model(fn_wrapper)\n","/content/ai-toolkit/extensions_built_in/sd_trainer/SDTrainer.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  self.scaler = torch.cuda.amp.GradScaler()\n"]},{"output_type":"stream","name":"stdout","text":["{\n","    \"type\": \"sd_trainer\",\n","    \"training_folder\": \"/content/output\",\n","    \"device\": \"cuda:0\",\n","    \"network\": {\n","        \"type\": \"lora\",\n","        \"linear\": 16,\n","        \"linear_alpha\": 16\n","    },\n","    \"save\": {\n","        \"dtype\": \"float16\",\n","        \"save_every\": 250,\n","        \"max_step_saves_to_keep\": 4\n","    },\n","    \"datasets\": [\n","        {\n","            \"folder_path\": \"/content/dataset\",\n","            \"caption_ext\": \"txt\",\n","            \"caption_dropout_rate\": 0.05,\n","            \"shuffle_tokens\": false,\n","            \"cache_latents_to_disk\": true,\n","            \"resolution\": [\n","                512,\n","                768,\n","                1024\n","            ]\n","        }\n","    ],\n","    \"train\": {\n","        \"batch_size\": 1,\n","        \"steps\": 4000,\n","        \"gradient_accumulation_steps\": 1,\n","        \"train_unet\": true,\n","        \"train_text_encoder\": false,\n","        \"content_or_style\": \"balanced\",\n","        \"gradient_checkpointing\": true,\n","        \"noise_scheduler\": \"flowmatch\",\n","        \"optimizer\": \"adamw8bit\",\n","        \"lr\": 0.0004,\n","        \"ema_config\": {\n","            \"use_ema\": true,\n","            \"ema_decay\": 0.99\n","        },\n","        \"dtype\": \"bf16\"\n","    },\n","    \"model\": {\n","        \"name_or_path\": \"black-forest-labs/FLUX.1-dev\",\n","        \"is_flux\": true,\n","        \"quantize\": true\n","    },\n","    \"sample\": {\n","        \"sampler\": \"flowmatch\",\n","        \"sample_every\": 250,\n","        \"width\": 1024,\n","        \"height\": 1024,\n","        \"prompts\": [\n","            \"my_first_flux_lora_v1\",\n","            \"my_first_flux_lora_v1\",\n","            \"my_first_flux_lora_v1\",\n","            \"my_first_flux_lora_v1\",\n","            \"my_first_flux_lora_v1\",\n","            \"my_first_flux_lora_v1\",\n","            \"my_first_flux_lora_v1\",\n","            \"my_first_flux_lora_v1\",\n","            \"my_first_flux_lora_v1\"\n","        ],\n","        \"neg\": \"\",\n","        \"seed\": 42,\n","        \"walk_seed\": true,\n","        \"guidance_scale\": 4,\n","        \"sample_steps\": 20\n","    }\n","}\n","Using EMA\n","\n","#############################################\n","# Running job: my_first_flux_lora_v1\n","#############################################\n","\n","\n","Running  1 process\n","Loading Flux model\n","Loading transformer\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["transformer/config.json:   0%|          | 0.00/378 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ce342c2b355443baeaaf794e5d6d3a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["(…)ion_pytorch_model.safetensors.index.json:   0%|          | 0.00/121k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f9dc90994574cac992aaebdb8c78535"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["(…)pytorch_model-00001-of-00003.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d4a5a78510f4425969ec93af9819ec7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["(…)pytorch_model-00002-of-00003.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2e4910fa8a04ba6bcc57cb17c839c0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["(…)pytorch_model-00003-of-00003.safetensors:   0%|          | 0.00/3.87G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"512d9cea35134017bd6cc3cfadef9e8e"}},"metadata":{}},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 23.06 MiB is free. Process 25095 has 14.72 GiB memory in use. Of the allocated memory 14.61 GiB is allocated by PyTorch, and 17.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-8519949f2c4c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_to_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/ai-toolkit/toolkit/job.py\u001b[0m in \u001b[0;36mrun_job\u001b[0;34m(config, name)\u001b[0m\n\u001b[1;32m     41\u001b[0m ):\n\u001b[1;32m     42\u001b[0m     \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/ai-toolkit/jobs/ExtensionJob.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocess\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/ai-toolkit/jobs/process/BaseSDTrainProcess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         )\n\u001b[1;32m   1266\u001b[0m         \u001b[0;31m# run base sd process run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_torch_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/ai-toolkit/toolkit/stable_diffusion_model.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_vram\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0;31m# for low v ram, we leave it on the cpu. Quantizes slower, but allows training on primary gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m                 \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantize_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m             \u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/models/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1029\u001b[0m                     \u001b[0;34mf\"The current device is `{self.device}`. If you intended to move the model, please install bitsandbytes >= 0.43.2.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 )\n\u001b[0;32m-> 1031\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m     \u001b[0;31m# Taken from `transformers`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     def register_full_backward_pre_hook(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1324\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m                     )\n\u001b[0;32m-> 1326\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1327\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 23.06 MiB is free. Process 25095 has 14.72 GiB memory in use. Of the allocated memory 14.61 GiB is allocated by PyTorch, and 17.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"]}]},{"cell_type":"markdown","source":["## Done\n","\n","Check your ourput dir and get your slider\n"],"metadata":{"id":"Hblgb5uwW5SD"}}]}